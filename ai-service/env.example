# Flask AI Service Configuration

# Service Configuration
PORT=5001
DEBUG=false
FLASK_ENV=production

# Hugging Face Configuration
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Model Cache Location (optional - customize where models are stored)
# HF_HOME=D:\AI_Models\huggingface
# HUGGINGFACE_HUB_CACHE=D:\AI_Models\huggingface\hub
# TRANSFORMERS_CACHE=D:\AI_Models\huggingface\transformers

# Model Configuration
PRIMARY_MODEL=Qwen/Qwen2.5-1.5B-Instruct
SUMMARIZATION_MODEL=facebook/bart-large-cnn
SENTIMENT_MODEL=cardiffnlp/twitter-roberta-base-sentiment-latest

# Performance Settings
CUDA_VISIBLE_DEVICES=0
TORCH_DTYPE=float16
MAX_MEMORY=8GB
DEVICE_MAP=auto

# Processing Limits
MAX_INPUT_LENGTH=2048
MAX_OUTPUT_LENGTH=512
BATCH_SIZE=1
TEMPERATURE=0.7

# Logging
LOG_LEVEL=INFO
LOG_FILE=ai-service.log 